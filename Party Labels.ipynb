{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011b3374",
   "metadata": {},
   "source": [
    "## Adding Party Affiliation to Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9b0720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efa0065",
   "metadata": {},
   "source": [
    "### Read in processed speeches and state abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b12c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Results/All_speeches_labelled.csv')\n",
    "abrv = pd.read_csv(\"Results/year_names/state_abrv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf9dfe2",
   "metadata": {},
   "source": [
    "### This process was performed manually for each year after iterative key matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "id": "06161fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 805/805 [00:23<00:00, 34.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original DF length was - 40363\n",
      "removed 7282 or 0.180413\n"
     ]
    }
   ],
   "source": [
    "cong = 102 # Congress to perform matching on\n",
    "\n",
    "# original subset\n",
    "oFrame = df.loc[df.congress == cong]\n",
    "\n",
    "# take relevant data and transform state names to abbreviations\n",
    "Frame = oFrame.groupby('speaker',as_index=False).first()[['speaker','first_name','last_name','state_x','gender']]\n",
    "Frame = Frame.merge(abrv[['State','Postal']],left_on='state_x',right_on='State',how='left')\n",
    "\n",
    "\n",
    "# access ProPublica House Member Database\n",
    "rq = requests.get(f'https://api.propublica.org/congress/v1/{cong}/house/members.json',\n",
    "                  headers={\"X-API-Key\":'WDmcjspeHVFMDSmrIZ3NV2gKAESs5vldAS8rz3X6'})\n",
    "ref = pd.DataFrame(json.loads(rq.text)['results'][0]['members'])\n",
    "\n",
    "# extract relevant information and make unique representative identifier\n",
    "ref = ref[['last_name','first_name','party','state','gender']]\n",
    "ref['unique_ID'] = ref.apply(lambda x:' '.join([x.first_name,x.last_name,x.state]),1)\n",
    "\n",
    "# CapitalCase all names to match with record\n",
    "ref['last_name'] = ref.last_name.str.upper() \n",
    "ref['first_name'] = ref.first_name.str.upper()\n",
    "\n",
    "# Iterative key matching\n",
    "Name_dict = {}\n",
    "for i,j in Frame.iterrows():\n",
    "    sub_ref = ref.loc[ref.last_name == j.last_name]\n",
    "    if len(sub_ref) > 1: # if more than one match after last name go to state\n",
    "        sub_ref = sub_ref.loc[sub_ref.state == j.Postal]\n",
    "        if len(sub_ref) > 1: # if more than one match after state go to gender\n",
    "            sub_ref = sub_ref.loc[sub_ref.gender == j.gender]\n",
    "            if len(sub_ref) > 1: # if more than one match after gender go to first name\n",
    "                sub_ref = sub_ref.loc[sub_ref.first_name == j.first_name] \n",
    "    \n",
    "    # if there are no records, add a blank line for manual coding later\n",
    "    if len(sub_ref) == 0:\n",
    "        sub_ref = pd.DataFrame([{\"speaker\":j.speaker}])\n",
    "    else:\n",
    "        sub_ref = sub_ref.reset_index()\n",
    "        sub_ref['speaker'] = j.speaker\n",
    "    Name_dict[j.speaker] = sub_ref\n",
    "\n",
    "# record Keeping and output\n",
    "longer = []\n",
    "Results = []\n",
    "for val in Name_dict.values():\n",
    "    if len(val) == 1:\n",
    "        Results.append(val)\n",
    "    if len(val) > 1:\n",
    "        longer.append(val)\n",
    "Result_df = pd.concat(Results)\n",
    "\n",
    "print(\"Total Number from Ref - \",len(ref))\n",
    "print(\"Single Found - \",len(Result_df.unique_ID.unique()))\n",
    "print(\"\\nNone Found - \",sum(Result_df.last_name.isnull()))\n",
    "print('Multiple Found - ',len(longer))\n",
    "\n",
    "Result_df.to_csv(f'Results/year_names/{cong}_.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6d7e9",
   "metadata": {},
   "source": [
    "# Put it all back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6daed0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Cleaned = []\n",
    "for cong in range(98,115):\n",
    "    sub_df = df.loc[df.congress == cong]\n",
    "    ref_df = pd.read_csv(f'Results/year_names/{cong}_.csv')\n",
    "    ref_df = ref_df[['unique_ID','party','gender','speaker']]\n",
    "    merged = sub_df.merge(ref_df,on='speaker',how='left')\n",
    "    Cleaned.append(merged)\n",
    "    \n",
    "Final = pd.concat(Cleaned)\n",
    "\n",
    "Final = Final.drop(['Unnamed: 0','Unnamed: 0.1','Unnamed: 0.1.1','state_y',\n",
    " 'name','party_x', 'chamber_y', 'year_x', 'party_y', 'gender_x', 'int_year'],1)\n",
    "\n",
    "Final.columns = ['speech_id','speech_text', 'chamber', 'date', 'number_within_file',\n",
    " 'speaker', 'first_name', 'last_name', 'state', 'line_start', 'line_end', 'file',\n",
    " 'char_count', 'word_count', 'speech_processed', 'congress', 'window_topic_id',\n",
    " 'topic_weight', 'year', 'topic_id', 'dynamic_label', 'unique_ID', 'party', 'gender']\n",
    "\n",
    "Final.to_csv('Results/All_speeches_labelled.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
