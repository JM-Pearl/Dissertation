{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0686d0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting corpus-toolkit\n",
      "  Downloading corpus_toolkit-0.32-py3-none-any.whl (1.7 MB)\n",
      "     |████████████████████████████████| 1.7 MB 27.0 MB/s            \n",
      "\u001b[?25hInstalling collected packages: corpus-toolkit\n",
      "Successfully installed corpus-toolkit-0.32\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install corpus-toolkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a36c9aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It appears that you do not have spacy installed on your computer. Without installing Spacy, the tag(), and tag_corpus() functions won't work properly.\n",
      "It appears that you haven't downloaded the default language model for Spacy 'en_core_web_sm'. If you intend to tag/parse your corpus, please make sure you have a model downloaded. If you wish to use a model other than the default one, then load it before proceeding: 'nlp = spacy.load('model_name')'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from multiprocess import Pool\n",
    "from corpus_toolkit import corpus_tools as ct\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import boto3\n",
    "client = boto3.client('s3')\n",
    "\n",
    "# Code from https://github.com/derekgreene/dynamic-nmf\n",
    "%run Greene_dnmf.py\n",
    "\n",
    "# get procedural stop words\n",
    "%run procedural_stop_words.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bfa4f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_rankings(H,terms,ntop):\n",
    "    term_rankings = []\n",
    "    for topic_index in range(H.shape[0]):\n",
    "        top_indices = np.argsort(H[topic_index,:])[::-1]\n",
    "        term_ranking = [terms[i] for i in top_indices[:ntop]]\n",
    "        term_rankings.append(term_ranking)\n",
    "    return term_rankings\n",
    "\n",
    "def get_top_words(vect):\n",
    "    splits = [[z for z in i.split() if z in vocab] for i in vect]\n",
    "    docs = [x for sublist in splits for x in sublist]\n",
    "    counts = Counter(docs)\n",
    "    top_10 = [i[0] for i in counts.most_common()][:20]\n",
    "    return top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d3b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_window_NMF(info):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reads in data for a given congress, runs NMF models for every year \n",
    "    in that congress for a specific party.\n",
    "    \n",
    "    info: tuple of type (Party, congress)\n",
    "    \"\"\"\n",
    "    party,congress = info\n",
    "\n",
    "    k = 50\n",
    "    \n",
    "    # read in data from S3\n",
    "    DF = pd.read_csv(client.get_object(Bucket='ascsagemaker',\n",
    "                                       Key=f'JMP_congressional_nmf/House_bigrams/{congress:0>3}_fixed_party.csv')['Body'])\n",
    "    \n",
    "    # remove speeches with no party labels\n",
    "    DF = DF.loc[-DF.party_y.isnull()]\n",
    "\n",
    "    # partse to only the house and party of interest\n",
    "    DF = DF.loc[(DF.chamber_x == 'H')]\n",
    "\n",
    "    DF['date'] = pd.to_datetime(DF.date)  # to date time\n",
    "    \n",
    "    years = pd.to_datetime(DF.date).dt.year.unique() # what years are included in this congress\n",
    "    if congress == 112:  #  112th congress includes overlap year with 113th\n",
    "        years = years[:2]\n",
    "    models = []\n",
    "    \n",
    "    #  for each year run a NMF window topic model\n",
    "    for year in years:\n",
    "        sub_df = DF.loc[DF.date.dt.year == year]\n",
    "        \n",
    "        # prepare TfIDF DTM\n",
    "        vectorizer = TfidfVectorizer(min_df=0.001,max_df=0.30,stop_words=procedural_stop_words,use_idf=True)\n",
    "        dtm = vectorizer.fit_transform(sub_df.speech_processed)\n",
    "        vocab = vectorizer.get_feature_names()\n",
    "\n",
    "        # run model\n",
    "        model = NMF(n_components=k,max_iter=5000,init='nndsvd')\n",
    "        W = model.fit_transform(dtm)\n",
    "        H = model.components_\n",
    "        print(f'{party} - {year} - {len(sub_df)} speeches')\n",
    "        \n",
    "        # return information packet\n",
    "        models.append({\"W\":W,\"H\":H,\"vocab\":vocab,\"window_labels\":[f'{party}_{year}_{i}' for i in range(100)],\"DF_index\":DF.index})\n",
    "        \n",
    "    return models,DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e535598b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep - 1983 - 19450 speeches\n",
      "Rep - 1984 - 20144 speeches\n"
     ]
    }
   ],
   "source": [
    "mod,DF = run_window_NMF(('Rep',98))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9a13e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_1983 = DF.loc[DF.date.dt.year == 1983]\n",
    "DF_1983['assigned_topic'] = mod[0]['W'].argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f832c786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['woman',\n",
       " 'era',\n",
       " 'equal_right',\n",
       " 'abortion',\n",
       " 'constitution',\n",
       " 'women',\n",
       " 'right',\n",
       " 'equal',\n",
       " 'economic_equity',\n",
       " 'discrimination']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_rankings(mod[0]['H'],mod[0]['vocab'],10)[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af988ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS = DF_1983.loc[DF_1983.assigned_topic == 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05b0d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_D = SS.loc[SS.party_y == 'D']\n",
    "SS_R = SS.loc[SS.party_y == 'R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e8688e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = ct.frequency(ct.tokenize([i for m in SS_D.speech_processed for i in m.split()]))\n",
    "R = ct.frequency(ct.tokenize([i for m in SS_R.speech_processed for i in m.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63ad2814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poor\t31.37620728722728\n",
      "poverty\t31.05427919233992\n",
      "pickle_amendment\t30.791244786506123\n",
      "retire\t30.717244205062347\n",
      "hispanic\t30.639241693061074\n",
      "president_reagan\t30.5567795328691\n",
      "rape\t30.46931669161876\n",
      "secretary\t30.37620728722728\n",
      "white_house\t30.276671613676367\n",
      "reagan\t30.276671613676367\n"
     ]
    }
   ],
   "source": [
    "corp_key = ct.keyness(D,R, effect = \"log-ratio\")\n",
    "ct.head(corp_key, hits = 10) #to display top hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "414e7b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratify\t31.266495327091516\n",
      "simplistic\t31.07385024914912\n",
      "unconstitutional\t30.381972544511452\n",
      "madison\t30.140964445007658\n",
      "unborn_child\t30.140964445007658\n",
      "senator_hatch\t30.140964445007658\n",
      "adoption\t30.003460921257723\n",
      "method\t30.003460921257723\n",
      "saline\t29.85145782781267\n",
      "strict\t29.85145782781267\n"
     ]
    }
   ],
   "source": [
    "corp_key = ct.keyness(R,D, effect = \"log-ratio\")\n",
    "ct.head(corp_key, hits = 10) #to display top hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06034783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
