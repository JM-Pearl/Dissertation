{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "281085de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from plotnine import ggplot, aes, geoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d29b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results/Official_TopicModel_80k.pkl','rb') as File:\n",
    "    models = joblib.load(File)\n",
    "    \n",
    "all_df = pd.read_csv('Results/All_speeches_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9cfb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data(year):\n",
    "    \"\"\"\n",
    "    convenience function for extracting X,Y data and dataframe\n",
    "    \"\"\"\n",
    "    sub_df = all_df.loc[all_df.year_x == year]\n",
    "    model = [mod for mod in models['window_models'] if mod['year'] == year][0]\n",
    "    \n",
    "    Y = np.array([1 if i == 'D' else 0 for i in sub_df.party_y])\n",
    "    X = model['W']\n",
    "    \n",
    "    return X,Y,sub_df[['party_y','speaker']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c9716a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set kfold split\n",
    "kfold = StratifiedKFold(n_splits=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "222d5be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lasso(X,Y,df,year,Cs=np.arange(0.1,1,0.1)):\n",
    "\n",
    "    Results = []\n",
    "    \n",
    "    # for values of C\n",
    "    for C in Cs:\n",
    "        \n",
    "        # fit and test model on all 10 cross validation folds\n",
    "        mod = LogisticRegression(penalty='l1',solver='liblinear',class_weight='balanced',C=C)\n",
    "        predict_probs = np.zeros(len(Y)) # empty array for speach probabilities\n",
    "        k_fold_vals = []\n",
    "        \n",
    "        for train_index, test_index in kfold.split(X, Y):\n",
    "            X_train,X_test = X[train_index],X[test_index]\n",
    "            Y_train,Y_test = Y[train_index],Y[test_index]\n",
    "            \n",
    "            # fit model predict test set\n",
    "            mod.fit(X_train,Y_train)\n",
    "            predictions = mod.predict(X_test)\n",
    "            \n",
    "            # get accuracy\n",
    "            speech_accuracy = sum([1 for ix,i in enumerate(predictions) if i == Y_test[ix]])/len(Y_test)\n",
    "            k_fold_vals.append(speech_accuracy)\n",
    "\n",
    "            # get probability of being Democrat for every speech\n",
    "            Dem_probs = [i[1] for i in mod.predict_proba(X_test)]\n",
    "            predict_probs[test_index] = Dem_probs\n",
    "\n",
    "        Results.append({\"C\":C,'mean_acc':np.mean(k_fold_vals),'std':np.std(k_fold_vals),'Dem_probs':predict_probs})\n",
    "\n",
    "    C_frame = pd.DataFrame(Results)\n",
    "\n",
    "    # select the best performing model\n",
    "    best_row = C_frame.sort_values(by='mean_acc',ascending=False).reset_index().loc[0].to_dict()\n",
    "    best_row['year'] = year\n",
    "    \n",
    "    # Speaker_accuracy\n",
    "    df['prob_party'] = predict_probs\n",
    "    partisan_assigned = df.groupby('speaker').prob_party.mean().reset_index()\n",
    "\n",
    "    partisan_assigned['predicted_party'] = partisan_assigned.prob_party.apply(lambda x: 'D' if x > 0.5 else 'R')\n",
    "\n",
    "    correct_speaker = sum(df.groupby('speaker').party_y.first().reset_index()\n",
    "                     .merge(partisan_assigned,on='speaker',how='inner')\n",
    "                     .apply(lambda x: 1 if x.party_y == x.predicted_party else 0,1))\n",
    "    \n",
    "    # speaker accuracy overall\n",
    "    best_row['speaker_acc'] = correct_speaker/len(partisan_assigned)\n",
    "    \n",
    "    speaker_party_true = df.groupby('speaker').party_y.first().reset_index()\n",
    "    speaker_party_true = speaker_party_true.loc[speaker_party_true.party_y != 'I']\n",
    "    speaker_party_true = speaker_party_true.merge(partisan_assigned,on='speaker').groupby('party_y')\n",
    "\n",
    "    # mean probability and std for Dem and Rep speakers\n",
    "    best_row['Dem_speaker_mean'],best_row['Rep_speaaker_mean'] = speaker_party_true.prob_party.mean()\n",
    "    best_row['Dem_speaker_std'],best_row['Rep_speaker_std'] = speaker_party_true.prob_party.std()\n",
    "        \n",
    "    # refit on all data to get coefficients\n",
    "    coefs = LogisticRegression(penalty='l1',solver='liblinear',class_weight='balanced',C=best_row['C']).fit(X,Y).coef_\n",
    "    best_row['coefs'] = coefs\n",
    "    \n",
    "    return best_row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a564854",
   "metadata": {},
   "source": [
    "## Run Every Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f120aaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [04:10<00:00,  7.60s/it]\n"
     ]
    }
   ],
   "source": [
    "Years = []\n",
    "for year in tqdm(range(1983,2016)):\n",
    "    X,Y,df = select_data(year)\n",
    "    Years.append(run_lasso(X,Y,df,year))\n",
    "LASSO_Results = pd.DataFrame(Years)\n",
    "LASSO_Results = LASSO_Results.drop('Dem_probs',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36f7b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "LASSO_Results.to_csv('Results/Lasso.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90605ab1",
   "metadata": {},
   "source": [
    "## Null Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "875d11ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_null_model(X,Y,df,year,n=200):\n",
    "    C = LASSO_Results.loc[LASSO_Results.year == year,'C'].values\n",
    "    iterations = []\n",
    "    for r in range(n):\n",
    "        np.random.shuffle(Y)\n",
    "        null = run_lasso(X,Y,df,year,Cs=C)\n",
    "        null['iter'] = r\n",
    "        iterations.append(null)\n",
    "    return pd.DataFrame(iterations).drop('Dem_probs',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c38564c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [1:08:03<00:00, 123.74s/it]\n"
     ]
    }
   ],
   "source": [
    "Years_null = []\n",
    "for year in tqdm(range(1983,2016)):\n",
    "    X,Y,df = select_data(year)\n",
    "    Years_null.append(run_null_model(X,Y,df,year))\n",
    "NULL_LASSO_Results = pd.concat(Years_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ba29bae",
   "metadata": {},
   "outputs": [],
   "source": [
    " NULL_LASSO_Results.to_csv('Results/Null_Results_Lasso.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25b7b01",
   "metadata": {},
   "source": [
    "## With SVC"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
