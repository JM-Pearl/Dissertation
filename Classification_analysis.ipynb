{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e04fb13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from plotnine import ggplot, aes, geoms\n",
    "\n",
    "# get procedural stop words\n",
    "%run procedural_stop_words.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6c6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results/Official_TopicModel_80k.pkl','rb') as File:\n",
    "    models = joblib.load(File)\n",
    "    \n",
    "all_df = pd.read_csv('Results/All_speeches_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1be696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data(year):\n",
    "    \"\"\"\n",
    "    convenience function for extracting X,Y data and dataframe\n",
    "    \"\"\"\n",
    "    sub_df = all_df.loc[all_df.year_x == year]\n",
    "    model = [mod for mod in models['window_models'] if mod['year'] == year][0]\n",
    "    \n",
    "    Y = np.array([1 if i == 'D' else 0 for i in sub_df.party_y])\n",
    "    X = model['W']\n",
    "    \n",
    "    return X,Y,sub_df[['party_y','speaker']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e857a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set kfold split\n",
    "kfold = StratifiedKFold(n_splits=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6b08723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X,Y,df,year,type='lasso',Cs=np.arange(0.1,1,0.1)):\n",
    "\n",
    "    Results = []\n",
    "    \n",
    "    # for values of C\n",
    "    for C in Cs:\n",
    "        \n",
    "        # fit and test model on all 10 cross validation folds\n",
    "        if type == 'lasso':\n",
    "            mod = LogisticRegression(penalty='l1',solver='liblinear',class_weight='balanced',C=C)\n",
    "        elif type == 'svc':\n",
    "            svc = LinearSVC(penalty='l1',class_weight='balanced',C=C,dual=False)\n",
    "            mod = CalibratedClassifierCV(svc)\n",
    "            \n",
    "        predict_probs = np.zeros(len(Y)) # empty array for speach probabilities\n",
    "        k_fold_vals = []\n",
    "        \n",
    "        for train_index, test_index in kfold.split(X, Y):\n",
    "            X_train,X_test = X[train_index],X[test_index]\n",
    "            Y_train,Y_test = Y[train_index],Y[test_index]\n",
    "            \n",
    "            # fit model predict test set\n",
    "            mod.fit(X_train,Y_train)\n",
    "            predictions = mod.predict(X_test)\n",
    "            \n",
    "            # get accuracy\n",
    "            speech_accuracy = sum([1 for ix,i in enumerate(predictions) if i == Y_test[ix]])/len(Y_test)\n",
    "            k_fold_vals.append(speech_accuracy)\n",
    "\n",
    "            # get probability of being Democrat for every speech\n",
    "            Dem_probs = [i[1] for i in mod.predict_proba(X_test)]\n",
    "            predict_probs[test_index] = Dem_probs\n",
    "\n",
    "        Results.append({\"C\":C,'mean_acc':np.mean(k_fold_vals),'std':np.std(k_fold_vals),'Dem_probs':predict_probs})\n",
    "\n",
    "    C_frame = pd.DataFrame(Results)\n",
    "\n",
    "    # select the best performing model\n",
    "    best_row = C_frame.sort_values(by='mean_acc',ascending=False).reset_index().loc[0].to_dict()\n",
    "    best_row['year'] = year\n",
    "    \n",
    "    # Speaker_accuracy\n",
    "    df['prob_party'] = predict_probs\n",
    "    partisan_assigned = df.groupby('speaker').prob_party.mean().reset_index()\n",
    "\n",
    "    partisan_assigned['predicted_party'] = partisan_assigned.prob_party.apply(lambda x: 'D' if x > 0.5 else 'R')\n",
    "\n",
    "    correct_speaker = sum(df.groupby('speaker').party_y.first().reset_index()\n",
    "                     .merge(partisan_assigned,on='speaker',how='inner')\n",
    "                     .apply(lambda x: 1 if x.party_y == x.predicted_party else 0,1))\n",
    "    \n",
    "    # speaker accuracy overall\n",
    "    best_row['speaker_acc'] = correct_speaker/len(partisan_assigned)\n",
    "    \n",
    "    speaker_party_true = df.groupby('speaker').party_y.first().reset_index()\n",
    "    speaker_party_true = speaker_party_true.loc[speaker_party_true.party_y != 'I']\n",
    "    speaker_party_true = speaker_party_true.merge(partisan_assigned,on='speaker').groupby('party_y')\n",
    "\n",
    "    # mean probability and std for Dem and Rep speakers\n",
    "    best_row['Dem_speaker_mean'],best_row['Rep_speaaker_mean'] = speaker_party_true.prob_party.mean()\n",
    "    best_row['Dem_speaker_std'],best_row['Rep_speaker_std'] = speaker_party_true.prob_party.std()\n",
    "        \n",
    "    # refit on all data to get coefficients\n",
    "    coefs = LogisticRegression(penalty='l1',solver='liblinear',class_weight='balanced',C=best_row['C']).fit(X,Y).coef_\n",
    "    best_row['coefs'] = coefs\n",
    "    \n",
    "    return best_row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec02f6",
   "metadata": {},
   "source": [
    "## Run LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c7e1e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [04:10<00:00,  7.60s/it]\n"
     ]
    }
   ],
   "source": [
    "Years = []\n",
    "for year in tqdm(range(1983,2016)):\n",
    "    X,Y,df = select_data(year)\n",
    "    Years.append(run_model(X,Y,df,year))\n",
    "LASSO_Results = pd.DataFrame(Years)\n",
    "LASSO_Results = LASSO_Results.drop('Dem_probs',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f51ee85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LASSO_Results.to_csv('Results/Lasso.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4177f854",
   "metadata": {},
   "source": [
    "## Null Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e3fd2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_null_model(X,Y,df,year,n=200):\n",
    "    C = LASSO_Results.loc[LASSO_Results.year == year,'C'].values\n",
    "    iterations = []\n",
    "    for r in range(n):\n",
    "        np.random.shuffle(Y)\n",
    "        null = run_model(X,Y,df,year,Cs=C)\n",
    "        null['iter'] = r\n",
    "        iterations.append(null)\n",
    "    return pd.DataFrame(iterations).drop('Dem_probs',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b10a4867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [1:08:03<00:00, 123.74s/it]\n"
     ]
    }
   ],
   "source": [
    "Years_null = []\n",
    "for year in tqdm(range(1983,2016)):\n",
    "    X,Y,df = select_data(year)\n",
    "    Years_null.append(run_null_model(X,Y,df,year))\n",
    "NULL_LASSO_Results = pd.concat(Years_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ece3877",
   "metadata": {},
   "outputs": [],
   "source": [
    " NULL_LASSO_Results.to_csv('Results/Null_Results_Lasso.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ece036",
   "metadata": {},
   "source": [
    "## With SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6fcfbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [14:40<00:00, 26.69s/it]\n"
     ]
    }
   ],
   "source": [
    "Years_SVC = []\n",
    "for year in tqdm(range(1983,2016)):\n",
    "    X,Y,df = select_data(year)\n",
    "    Years_SVC.append(run_model(X,Y,df,year,type='svc',Cs=[0.1, 1, 10, 100, 1000]))\n",
    "SVC_Results = pd.DataFrame(Years_SVC)\n",
    "SVC_Results = SVC_Results.drop('Dem_probs',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5c3f40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_Results.to_csv(\"Results/SVC.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f227ecaa",
   "metadata": {},
   "source": [
    "## Classification result robustness\n",
    "\n",
    "To ensure that classificaiton results are robust to the types of features that are entered into the models. More specifically, for each year four topic models will be built with alternative K (20,60,80,100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4d208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_NMF(year,k):\n",
    "    sub_df = all_df.loc[all_df.year_x == year]\n",
    "    vectorizer = TfidfVectorizer(min_df=0.001,max_df=0.3,stop_words=procedural_stop_words,use_idf=True,)\n",
    "    dtm = vectorizer.fit_transform(sub_df.speech_processed)\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "    \n",
    "    model = NMF(n_components=k,max_iter=5000,init='nndsvd')\n",
    "    X = model.fit_transform(dtm)\n",
    "    Y = np.array([1 if i == 'D' else 0 for i in sub_df.party_y])\n",
    "    return X,Y,sub_df[['party_y','speaker']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "411b712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustness_check(k):\n",
    "    Years = []\n",
    "    for year in tqdm(range(1983,2016)):\n",
    "        X,Y,df = run_NMF(year,k)\n",
    "        Years.append(run_model(X,Y,df,year))\n",
    "    Results = pd.DataFrame(Years)\n",
    "    Results = Results.drop('Dem_probs',1)\n",
    "    Results['k'] = k\n",
    "    return Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c3321",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = pd.read_csv('Results/Lasso.csv')\n",
    "l1['k'] = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a4566bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [09:46<00:00, 17.78s/it]\n"
     ]
    }
   ],
   "source": [
    "Results_20 = robustness_check(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f143ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [26:44<00:00, 48.62s/it]\n"
     ]
    }
   ],
   "source": [
    "Results_60 = robustness_check(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3662ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [41:34<00:00, 75.58s/it]\n"
     ]
    }
   ],
   "source": [
    "Results_80 = robustness_check(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5023717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [1:11:39<00:00, 130.28s/it]\n"
     ]
    }
   ],
   "source": [
    "Results_100 = robustness_check(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f89703b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_models = pd.concat([l1,Results_20,Results_60,Results_80,Results_100])\n",
    "All_models['k'] = All_models.k.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7281b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_models.to_csv('Results/Robustness.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10347321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
