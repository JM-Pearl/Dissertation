{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed7aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "client = boto3.client('s3')\n",
    "\n",
    "# Code from https://github.com/derekgreene/dynamic-nmf\n",
    "%run Greene_dnmf.py\n",
    "\n",
    "# get procedural stop words\n",
    "%run procedural_stop_words.py\n",
    "\n",
    "from multiprocess import Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5acb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_theme = theme(panel_background=element_blank(),\n",
    "                    axis_line=element_line(),\n",
    "                    figure_size=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9016b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results/Official_TopicModel_80k.pkl','rb') as File:\n",
    "    models = joblib.load(File)\n",
    "    \n",
    "all_df = pd.read_csv('Results/All_speeches_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac357601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_rankings(H,terms,ntop):\n",
    "    term_rankings = []\n",
    "    for topic_index in range(H.shape[0]):\n",
    "        top_indices = np.argsort(H[topic_index,:])[::-1]\n",
    "        term_ranking = [terms[i] for i in top_indices[:ntop]]\n",
    "        term_rankings.append(term_ranking)\n",
    "    return term_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c95d35ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data(year):\n",
    "    sub_df = all_df.loc[all_df.year_x == year]\n",
    "    model = [mod for mod in models['window_models'] if mod['year'] == year][0]\n",
    "    \n",
    "    Y = [1 if i == 'D' else 0 for i in sub_df.party_y]\n",
    "    X = model['W']\n",
    "    \n",
    "    \n",
    "    return X,Y,sub_df[['party_y','speaker']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36b76b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a57ea2fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_transform() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7dccf750533f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit_transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "StandardScaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "224cd8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X,Y,df):\n",
    "    _models = []\n",
    "    for C in np.arange(0.1,1,0.1):\n",
    "        mod = LogisticRegression(penalty='l1',solver='liblinear',class_weight='balanced',C=C)\n",
    "        mod.fit(X,Y)\n",
    "        predictions = mod.predict(X)\n",
    "        speech_accuracy = sum([1 for ix,i in enumerate(predictions) if i == Y[ix]])/len(Y)\n",
    "        \n",
    "        speech_probs = [i[1] for i in mod.predict_proba(X)]\n",
    "        df['prob_party'] = speech_probs\n",
    "        \n",
    "        partisan_assigned = df.groupby('speaker').prob_party.mean().reset_index()\n",
    "        partisan_assigned['predicted_party'] = partisan_assigned.prob_party.apply(lambda x: 'D' if x > 0.5 else 'R')\n",
    "        correct_speaker = sum(df.groupby('speaker').party_y.first().reset_index()\n",
    "                             .merge(partisan_assigned,on='speaker',how='inner')\n",
    "                             .apply(lambda x: 1 if x.party_y == x.predicted_party else 0,1))\n",
    "\n",
    "        speaker_accuracy = correct_speaker/len(partisan_assigned)\n",
    "        _models.append({\"C\":C,'speech_accuracy':speech_accuracy,'speaker_accuracy':speaker_accuracy,'coefs':mod.coef_})\n",
    "    return pd.DataFrame(_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cd4fe13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:44<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for year in tqdm(range(1983,2017)):\n",
    "    X,Y,df = select_data(year)\n",
    "    mod_df = fit_model(X,Y,df)\n",
    "    records.append({\"year\":year,\n",
    "                    \"speaker_accuracy\":mod_df.speaker_accuracy.max(),\n",
    "                    \"speaker_acc_C\":mod_df.loc[mod_df.speaker_accuracy == mod_df.speaker_accuracy.max(),'C'].values[0],\n",
    "                    \"speaker_acc_coef\":mod_df.loc[mod_df.speaker_accuracy == mod_df.speaker_accuracy.max(),'coefs'].values[0],\n",
    "                    \"speech_accuracy\":mod_df.speech_accuracy.max(),\n",
    "                   \"speech_acc_C\":mod_df.loc[mod_df.speech_accuracy == mod_df.speech_accuracy.max(),'C'].values[0],\n",
    "                   \"speech_acc_coef\":mod_df.loc[mod_df.speech_accuracy == mod_df.speech_accuracy.max(),'coefs'].values[0]})\n",
    "    \n",
    "true_records = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76523b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>speaker_accuracy</th>\n",
       "      <th>speaker_acc_C</th>\n",
       "      <th>speaker_acc_coef</th>\n",
       "      <th>speech_accuracy</th>\n",
       "      <th>speech_acc_C</th>\n",
       "      <th>speech_acc_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1983</td>\n",
       "      <td>0.699234</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[[0.0, 0.859087542023104, -0.5206892923239224,...</td>\n",
       "      <td>0.599486</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[[0.0, 0.0, 0.0, -1.4959521475964013, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[[0.0, 0.0, -11.282313476002717, 0.0, -5.86440...</td>\n",
       "      <td>0.631702</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[[0.0, 0.0, -14.03327331974852, 0.069685493535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>0.708191</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[[0.0, -19.82308523381375, -5.754092998809567,...</td>\n",
       "      <td>0.607525</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[[0.0, -19.82308523381375, -5.754092998809567,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[[0.0, 8.559600746455118, -0.7342625371268254,...</td>\n",
       "      <td>0.601663</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[[0.0, 9.482713844706906, -0.9557675274864119,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>0.669329</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[[-5.261858005583338, -13.995375689957324, 0.0...</td>\n",
       "      <td>0.577853</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[[-2.5032975594148708, -13.483195354287819, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  speaker_accuracy  speaker_acc_C  \\\n",
       "0  1983          0.699234            0.8   \n",
       "1  1984          0.708333            0.3   \n",
       "2  1985          0.708191            0.9   \n",
       "3  1986          0.685714            0.6   \n",
       "4  1987          0.669329            0.7   \n",
       "\n",
       "                                    speaker_acc_coef  speech_accuracy  \\\n",
       "0  [[0.0, 0.859087542023104, -0.5206892923239224,...         0.599486   \n",
       "1  [[0.0, 0.0, -11.282313476002717, 0.0, -5.86440...         0.631702   \n",
       "2  [[0.0, -19.82308523381375, -5.754092998809567,...         0.607525   \n",
       "3  [[0.0, 8.559600746455118, -0.7342625371268254,...         0.601663   \n",
       "4  [[-5.261858005583338, -13.995375689957324, 0.0...         0.577853   \n",
       "\n",
       "   speech_acc_C                                    speech_acc_coef  \n",
       "0           0.3  [[0.0, 0.0, 0.0, -1.4959521475964013, 0.0, 0.0...  \n",
       "1           0.7  [[0.0, 0.0, -14.03327331974852, 0.069685493535...  \n",
       "2           0.9  [[0.0, -19.82308523381375, -5.754092998809567,...  \n",
       "3           0.8  [[0.0, 9.482713844706906, -0.9557675274864119,...  \n",
       "4           0.6  [[-2.5032975594148708, -13.483195354287819, 0....  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "846d170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_records.to_csv('Results/classification_results_with_coefs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531749c",
   "metadata": {},
   "source": [
    "### Chance models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_C = true_records.loc[true_records.year == year,'speaker_acc_C'].values[0]\n",
    "speech_C = true_records.loc[true_records.year == year,'speech_acc_C'].values[0]\n",
    "for i in tqdm(range(200),desc=f\"{year}: \"): # bootstrap sample\n",
    "    boot_df = df.sample(len(df),replace=True)\n",
    "    boot_x = X[boot_df.index]\n",
    "    boot_y = [Y[_] for _ in boot_df.index]\n",
    "\n",
    "    # Model for speaker accuracy\n",
    "    mod = LogisticRegression(penalty='l1',solver='liblinear',class_weight='balanced',C=speaker_C)\n",
    "    mod.fit(boot_x,boot_y)\n",
    "\n",
    "    speech_probs = [i[1] for i in mod.predict_proba(boot_x)]\n",
    "    boot_df['prob_party'] = speech_probs\n",
    "\n",
    "    partisan_assigned = boot_df.groupby('speaker').prob_party.mean().reset_index()\n",
    "    partisan_assigned['predicted_party'] = partisan_assigned.prob_party.apply(lambda x: 'D' if x > 0.5 else 'R')\n",
    "    correct_speaker = sum(df.groupby('speaker').party_y.first().reset_index()\n",
    "                         .merge(partisan_assigned,on='speaker',how='inner')\n",
    "                         .apply(lambda x: 1 if x.party_y == x.predicted_party else 0,1))\n",
    "\n",
    "    speaker_accuracy = correct_speaker/len(partisan_assigned)\n",
    "\n",
    "    # Model for Speech accuracy\n",
    "    mod = LogisticRegression(penalty='l1',solver='liblinear',class_weight='balanced',C=speech_C)\n",
    "    mod.fit(boot_x,boot_y)\n",
    "    predictions = mod.predict(boot_x)\n",
    "    speech_accuracy = sum([1 for ix,i in enumerate(predictions) if i == boot_y[ix]])/len(boot_y)\n",
    "\n",
    "    records.append({\"year\":year,\n",
    "                \"speaker_accuracy\":speaker_accuracy,\n",
    "                \"speech_accuracy\":speech_accuracy,\n",
    "                \"iteration\":i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1983: 100%|██████████| 200/200 [00:39<00:00,  5.12it/s]\n",
      "1984: 100%|██████████| 200/200 [00:35<00:00,  5.56it/s]\n",
      "1985: 100%|██████████| 200/200 [00:46<00:00,  4.29it/s]\n",
      "1986: 100%|██████████| 200/200 [00:37<00:00,  5.38it/s]\n",
      "1987: 100%|██████████| 200/200 [00:40<00:00,  4.99it/s]\n",
      "1988: 100%|██████████| 200/200 [00:37<00:00,  5.37it/s]\n",
      "1989: 100%|██████████| 200/200 [00:34<00:00,  5.88it/s]\n",
      "1990: 100%|██████████| 200/200 [00:40<00:00,  4.88it/s]\n",
      "1991: 100%|██████████| 200/200 [00:36<00:00,  5.49it/s]\n",
      "1992: 100%|██████████| 200/200 [00:32<00:00,  6.09it/s]\n",
      "1993: 100%|██████████| 200/200 [00:36<00:00,  5.54it/s]\n",
      "1994: 100%|██████████| 200/200 [00:37<00:00,  5.36it/s]\n",
      "1995: 100%|██████████| 200/200 [00:54<00:00,  3.69it/s]\n",
      "1996: 100%|██████████| 200/200 [00:33<00:00,  5.90it/s]\n",
      "1997: 100%|██████████| 200/200 [00:39<00:00,  5.09it/s]\n",
      "1998: 100%|██████████| 200/200 [00:39<00:00,  5.09it/s]\n",
      "1999: 100%|██████████| 200/200 [00:38<00:00,  5.13it/s]\n",
      "2000: 100%|██████████| 200/200 [00:36<00:00,  5.55it/s]\n",
      "2001: 100%|██████████| 200/200 [00:34<00:00,  5.73it/s]\n",
      "2002: 100%|██████████| 200/200 [00:30<00:00,  6.58it/s]\n",
      "2003: 100%|██████████| 200/200 [00:35<00:00,  5.63it/s]\n",
      "2004: 100%|██████████| 200/200 [00:35<00:00,  5.56it/s]\n",
      "2005: 100%|██████████| 200/200 [00:34<00:00,  5.79it/s]\n",
      "2006: 100%|██████████| 200/200 [00:35<00:00,  5.60it/s]\n",
      "2007: 100%|██████████| 200/200 [00:46<00:00,  4.29it/s]\n",
      "2008: 100%|██████████| 200/200 [00:33<00:00,  5.96it/s]\n",
      "2009: 100%|██████████| 200/200 [00:33<00:00,  5.95it/s]\n",
      "2010: 100%|██████████| 200/200 [00:35<00:00,  5.71it/s]\n",
      "2011: 100%|██████████| 200/200 [00:37<00:00,  5.34it/s]\n",
      "2012: 100%|██████████| 200/200 [00:28<00:00,  6.91it/s]\n",
      "2013: 100%|██████████| 200/200 [00:33<00:00,  6.05it/s]\n",
      "2014: 100%|██████████| 200/200 [00:26<00:00,  7.59it/s]\n",
      "2015: 100%|██████████| 200/200 [00:32<00:00,  6.20it/s]\n",
      "2016: 100%|██████████| 200/200 [00:23<00:00,  8.46it/s]\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for year in range(1983,2017):\n",
    "    speaker_C = true_records.loc[true_records.year == year,'speaker_acc_C'].values[0]\n",
    "    speech_C = true_records.loc[true_records.year == year,'speech_acc_C'].values[0]\n",
    "    \n",
    "    X,Y,df = select_data(year)\n",
    "    \n",
    "    for i in tqdm(range(200),desc=f\"{year}: \"): \n",
    "        np.random.shuffle(Y)\n",
    "\n",
    "        # Model for speaker accuracy\n",
    "        mod = LogisticRegression(penalty='l1',solver='liblinear',class_weight='balanced',C=speaker_C)\n",
    "        mod.fit(X,Y)\n",
    "\n",
    "        speech_probs = [i[1] for i in mod.predict_proba(X)]\n",
    "        df['prob_party'] = speech_probs\n",
    "\n",
    "        partisan_assigned = df.groupby('speaker').prob_party.mean().reset_index()\n",
    "        partisan_assigned['predicted_party'] = partisan_assigned.prob_party.apply(lambda x: 'D' if x > 0.5 else 'R')\n",
    "        correct_speaker = sum(df.groupby('speaker').party_y.first().reset_index()\n",
    "                             .merge(partisan_assigned,on='speaker',how='inner')\n",
    "                             .apply(lambda x: 1 if x.party_y == x.predicted_party else 0,1))\n",
    "\n",
    "        speaker_accuracy = correct_speaker/len(partisan_assigned)\n",
    "\n",
    "        # Model for Speech accuracy\n",
    "        mod = LogisticRegression(penalty='l1',solver='liblinear',class_weight='balanced',C=speech_C)\n",
    "        mod.fit(X,Y)\n",
    "        predictions = mod.predict(X)\n",
    "        speech_accuracy = sum([1 for ix,i in enumerate(predictions) if i == Y[ix]])/len(Y)\n",
    "\n",
    "        records.append({\"year\":year,\n",
    "                    \"speaker_accuracy\":speaker_accuracy,\n",
    "                    \"speech_accuracy\":speech_accuracy,\n",
    "                    \"iteration\":i})\n",
    "    \n",
    "null_records = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a95a4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = pd.concat([null_records,true_records[['year','speaker_accuracy','speech_accuracy']]])\n",
    "combo.loc[combo.iteration.isnull(),'type']  = 'actual'\n",
    "combo.loc[-combo.iteration.isnull(),'type']  = 'null'\n",
    "combo.loc[combo.iteration.isnull(),'iteration']  = 11\n",
    "combo.to_csv('results_with_null.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4d0cfd",
   "metadata": {},
   "source": [
    "### Bootstrapped models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea7bfbec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a8068c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_boot(year):\n",
    "    records = []\n",
    "    X,Y,df = select_data(year)\n",
    "    speaker_C = true_records.loc[true_records.year == year,'speaker_acc_C'].values[0]\n",
    "    speech_C = true_records.loc[true_records.year == year,'speech_acc_C'].values[0]\n",
    "    for i in tqdm(range(1000),desc=f\"{year}: \"): # bootstrap sample\n",
    "        boot_df = df.sample(len(df),replace=True)\n",
    "        boot_x = X[boot_df.index]\n",
    "        boot_y = [Y[_] for _ in boot_df.index]\n",
    "        \n",
    "        # Model for speaker accuracy\n",
    "        mod = LogisticRegression(penalty='l1',solver='liblinear',class_weight='balanced',C=speaker_C)\n",
    "        mod.fit(boot_x,boot_y)\n",
    "        \n",
    "        speech_probs = [i[1] for i in mod.predict_proba(boot_x)]\n",
    "        boot_df['prob_party'] = speech_probs\n",
    "        \n",
    "        partisan_assigned = boot_df.groupby('speaker').prob_party.mean().reset_index()\n",
    "        partisan_assigned['predicted_party'] = partisan_assigned.prob_party.apply(lambda x: 'D' if x > 0.5 else 'R')\n",
    "        correct_speaker = sum(boot_df.groupby('speaker').party_y.first().reset_index()\n",
    "                             .merge(partisan_assigned,on='speaker',how='inner')\n",
    "                             .apply(lambda x: 1 if x.party_y == x.predicted_party else 0,1))\n",
    "\n",
    "        speaker_accuracy = correct_speaker/len(partisan_assigned)\n",
    "    \n",
    "        # Model for Speech accuracy\n",
    "        mod = LogisticRegression(penalty='l1',solver='liblinear',class_weight='balanced',C=speech_C)\n",
    "        mod.fit(boot_x,boot_y)\n",
    "        predictions = mod.predict(boot_x)\n",
    "        speech_accuracy = sum([1 for ix,i in enumerate(predictions) if i == boot_y[ix]])/len(boot_y)\n",
    "        \n",
    "        records.append({\"year\":year,\n",
    "                    \"speaker_accuracy\":speaker_accuracy,\n",
    "                    \"speech_accuracy\":speech_accuracy})\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b48e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1983: 100%|██████████| 1000/1000 [04:26<00:00,  3.76it/s]\n",
      "1984: 100%|██████████| 1000/1000 [04:31<00:00,  3.69it/s]\n",
      "1985: 100%|██████████| 1000/1000 [05:12<00:00,  3.20it/s]\n",
      "1986: 100%|██████████| 1000/1000 [04:20<00:00,  3.85it/s]\n",
      "1987: 100%|██████████| 1000/1000 [04:17<00:00,  3.89it/s]\n",
      "1988: 100%|██████████| 1000/1000 [03:54<00:00,  4.26it/s]\n",
      "1989: 100%|██████████| 1000/1000 [03:50<00:00,  4.34it/s]\n",
      "1990: 100%|██████████| 1000/1000 [04:20<00:00,  3.84it/s]\n",
      "1991: 100%|██████████| 1000/1000 [04:33<00:00,  3.66it/s]\n",
      "1992: 100%|██████████| 1000/1000 [03:39<00:00,  4.56it/s]\n",
      "1993: 100%|██████████| 1000/1000 [04:50<00:00,  3.44it/s]\n",
      "2006:  76%|███████▌  | 762/1000 [03:30<01:03,  3.75it/s]"
     ]
    }
   ],
   "source": [
    "boot_results = []\n",
    "for year in range(1983,2017):\n",
    "    boot_results.append(Run_boot(year))\n",
    "boot_df = pd.concat(boot_results)\n",
    "boot_df.to_csv('bootstrap_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282cb64d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
