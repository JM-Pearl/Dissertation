{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf648358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "%run procedural_stop_words.py\n",
    "procedural_stop_words.extend(['do','be','mr_speaker','have','time','other'])\n",
    "\n",
    "from tqdm import tqdm\n",
    "from plotnine import ggplot, aes, geoms\n",
    "\n",
    "# R package import \n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "R = ro.r\n",
    "pandas2ri.activate()\n",
    "\n",
    "from p_tqdm import p_map\n",
    "\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5705e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results/Official_TopicModel_80k.pkl','rb') as File:\n",
    "    models = joblib.load(File)\n",
    "    \n",
    "all_df = pd.read_csv('Results/All_speeches_labelled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0fce70",
   "metadata": {},
   "source": [
    "\n",
    "## For Speakers\n",
    "\n",
    "A massive-univariate technique in which every phrases is tested against the null-hypothesis that the frequency distribution of the word for Democrats and Republicans come from the same underlying distribution. This analysis is akin to the mass-univeraite analysis undertaken in basic neuroimaging research, where each voxel is analyzed independently given the same model. Results are of course corrected for multiple comparison using FDR correction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a9fd9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data(year,topic):\n",
    "    sub_df = all_df.loc[(all_df.year_y == year) & (all_df.dynamic_label == topic)]\n",
    "\n",
    "    # Linker for speaker party to speaker\n",
    "    name_party_link = sub_df[['speaker','party_y']].groupby('speaker').first().reset_index()\n",
    "\n",
    "    # term DTM\n",
    "    vectorizer = CountVectorizer(stop_words=procedural_stop_words,min_df=0.01,binary=True)\n",
    "    DTM = vectorizer.fit_transform(sub_df.speech_processed)\n",
    "    DTM = pd.DataFrame(DTM.toarray())\n",
    "\n",
    "    # sum term occurance by speaker and merge with party\n",
    "    DTM['speaker'] = list(sub_df['speaker'])\n",
    "    DTM = (DTM\n",
    "           .groupby('speaker')\n",
    "           .sum()\n",
    "           .reset_index()\n",
    "           .merge(name_party_link,on='speaker',how='left')\n",
    "           .drop('speaker',1)\n",
    "          )\n",
    "\n",
    "    DTM.columns = [f'x_{i}' for i in DTM.columns]\n",
    "    print(\"DTM of size - \",DTM.shape)\n",
    "    return DTM\n",
    "\n",
    "def run_poisson(col):\n",
    "    mod = R.glm(f'x_{col}~x_party_y',family='poisson',data=DTM)\n",
    "    effects = R.summary(mod).rx2('coefficients')\n",
    "    return {'col':col,'est':effects[1,0],'pval':effects[1,-1]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6731350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM of size -  (96, 1499)\n"
     ]
    }
   ],
   "source": [
    "DTM = select_data(1999,'abortion')\n",
    "\n",
    "start = time.time()\n",
    "estimates = [run_poisson(i) for i in range(len(DTM.columns) - 1)]\n",
    "print(time.time() - start)\n",
    "df= pd.DataFrame(estimates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "837fe56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>est</th>\n",
       "      <th>pval</th>\n",
       "      <th>fdr_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>-1.734601</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>767</td>\n",
       "      <td>-1.201303</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     col       est      pval  fdr_p\n",
       "10    10 -1.734601  0.000105   True\n",
       "767  767 -1.201303  0.000059   True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fdr_p'] = fdrcorrection(df.pval)[0]\n",
    "df.loc[df.fdr_p == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c372e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
