{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "110231da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"NUMEXPR_MAX_THREADS\"] = '36'\n",
    "\n",
    "import joblib\n",
    "import p_tqdm\n",
    "\n",
    "%run Frame_analysis_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13a297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('Results/All_speeches_labelled.csv')\n",
    "all_df = all_df.loc[all_df.party_y != 'I']\n",
    "\n",
    "combinations = []\n",
    "for year in range(1983,2017):\n",
    "    for topic in all_df.dynamic_label.unique():\n",
    "        combinations.append((year,topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "056c280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_similarity(year,topic,binary=True):\n",
    "    \"\"\"\n",
    "    run analysis for a given year and topic\n",
    "    \n",
    "    args:\n",
    "        - year: year to subset speeches\n",
    "        - topic: topic to subset speeches\n",
    "        - binary: if True, 1 for speech containing word else frequency within speech\n",
    "    returns:\n",
    "        - dictionary containing summary statistics and correlation dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # subset speeches\n",
    "    sub_df = all_df.loc[(all_df.year_y == year) & (all_df.dynamic_label == topic)]\n",
    "\n",
    "    if len(sub_df) > 0:\n",
    "\n",
    "        DTM = make_DTM(sub_df,binary=binary) # Make DTM\n",
    "        term_df = chiSq_df(DTM) # Make Chi_square frequency table\n",
    "        pre_drop_terms = DTM.columns[:-1] # record keeping\n",
    "        \n",
    "        # remove low value chi square terms (take top 200 terms)\n",
    "        term_df = term_df.sort_values(by='chi2',ascending=False)\n",
    "        drop_cols = list(term_df['terms'][200:])\n",
    "        DTM = DTM.drop(drop_cols,1)\n",
    "        term_df = term_df.head(200)\n",
    "        \n",
    "        corr_df = perform_correlations(DTM) # make correlation DF\n",
    "        \n",
    "        # calculate metrics\n",
    "        corr_df['weighted'] = corr_df['correlation']*corr_df['freq']\n",
    "        partisanship = corr_df['weighted'].sum()/corr_df['freq'].sum()\n",
    "        polarization = corr_df['weighted'].abs().sum()/corr_df['freq'].sum()\n",
    "        distance = cosine(term_df['D'],term_df['R'])\n",
    "        \n",
    "        return {\"results\":{'distance':distance,\n",
    "                    'polarization':polarization,\n",
    "                    'partisanship':partisanship,\n",
    "                    \"pre_termlength\":len(pre_drop_terms),\n",
    "                    'post_termlength':len(corr_df)},\n",
    "                'correlations':corr_df,\n",
    "                'topic':topic,\n",
    "                'year':year\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea3267",
   "metadata": {},
   "source": [
    "# Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92842175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016 healthcare: 100%|██████████| 2142/2142 [03:52<00:00,  9.23it/s]               \n"
     ]
    }
   ],
   "source": [
    "Results = []\n",
    "pbar = tqdm(combinations)\n",
    "for combination in pbar:\n",
    "    pbar.set_description(\"%s %s\"%combination)\n",
    "    year,topic = combination\n",
    "    f = run_similarity(year,topic,binary=True)\n",
    "    if f:\n",
    "        Results.append(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c27670",
   "metadata": {},
   "source": [
    "# Permutation analysis for null models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67f0b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_similarity_perm(year,topic,binary=True,perms=200):\n",
    "    sub_df = all_df.loc[(all_df.year_y == year) & (all_df.dynamic_label == topic)]\n",
    "    if len(sub_df) > 0:\n",
    "        \n",
    "        # get terms maintained from true results\n",
    "        true_corrs = [b['correlations'] for b in Results \n",
    "                   if b['topic'] == topic and b['year'] == year]\n",
    "\n",
    "        keep_terms = true_corrs[0].term.values\n",
    "        \n",
    "        DTM = make_DTM(sub_df,binary=binary) # Make DTM\n",
    "        pre_drop_terms = DTM.columns[:-1] # record keeping\n",
    "        drop_cols = [i for i in pre_drop_terms if i not in keep_terms]\n",
    "        DTM = DTM.drop(drop_cols,1)\n",
    "        \n",
    "        Nulls = []\n",
    "        for perm in range(perms):\n",
    "            term_df = chiSq_df(DTM,permute=True) # Make Chi_square frequency table\n",
    "            # remove low value chi square terms\n",
    "            term_df['chi2'] = term_df.loc[-term_df.terms.isin(drop_cols)]\n",
    "\n",
    "            corr_df = perform_correlations(DTM,permute=True) # make correlation DF\n",
    "\n",
    "            # calculate metrics\n",
    "            corr_df['weighted'] = corr_df['correlation']*corr_df['freq']\n",
    "            partisanship = corr_df['weighted'].sum()/corr_df['freq'].sum()\n",
    "            polarization = corr_df['weighted'].abs().sum()/corr_df['freq'].sum()\n",
    "            distance = cosine(term_df['D'],term_df['R'])\n",
    "\n",
    "            Nulls.append({'distance':distance,\n",
    "                        'polarization':polarization,\n",
    "                        'partisanship':partisanship,\n",
    "                        \"pre_termlength\":len(pre_drop_terms),\n",
    "                        'post_termlength':len(corr_df),\n",
    "                        'topic':topic,\n",
    "                        'year':year,\n",
    "                        'iter':perm})\n",
    "        return pd.DataFrame(Nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ca68e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f259bb565ba44333ae781a8b9079d8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_(x):\n",
    "    year,topic = x\n",
    "    f = run_similarity_perm(year,topic,binary=True)\n",
    "    if type(f) == pd.core.frame.DataFrame:\n",
    "        return f\n",
    "\n",
    "Null_Results = p_tqdm.p_map(run_,combinations,num_cpus=30)\n",
    "\n",
    "Null_DF = pd.concat(Null_Results)\n",
    "Null_DF.to_csv('Results/Null_Frame_Results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24dfccf",
   "metadata": {},
   "source": [
    "### Saving to disc and as CSV for visualization in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "997f59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results/Frame_results.pkl', 'wb') as File:\n",
    "    joblib.dump(Results,File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8adb9c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_DF = []\n",
    "for r in Results:\n",
    "    d = r['results']\n",
    "    d['year'] = r['year']\n",
    "    d['topic'] = r['topic']\n",
    "    Result_DF.append(d)\n",
    "Result_DF = pd.DataFrame(Result_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ccf2bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Null_DF['polarization_st'] = Null_DF.groupby('iter').polarization.transform(lambda x: (x-x.mean())/x.std())\n",
    "Null_DF['partisanship_st'] = Null_DF.groupby('iter').partisanship.transform(lambda x: (x-x.mean())/x.std())\n",
    "\n",
    "\n",
    "Result_DF['polarization_st'] = Result_DF.polarization.transform(lambda x: (x-x.mean())/x.std())\n",
    "Result_DF['partisanship_st'] = Result_DF.partisanship.transform(lambda x: (x-x.mean())/x.std())\n",
    "\n",
    "Null_DF['type'] = 'null'\n",
    "Result_DF['iter'] = 99\n",
    "Result_DF['type'] = 'true'\n",
    "\n",
    "Null_DF = Null_DF[['type','iter','year','topic','distance','polarization','polarization_st','partisanship','partisanship_st']]\n",
    "Result_DF = Result_DF[['type','iter','year','topic','distance','polarization','polarization_st','partisanship','partisanship_st']]\n",
    "\n",
    "combined = pd.concat([Result_DF,Null_DF])\n",
    "\n",
    "combined.to_csv('Results/True_and_Nulls_Frame.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4f271af",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = []\n",
    "for r in Results:\n",
    "    df = r['correlations']\n",
    "    df['year'] = r['year']\n",
    "    df['topic'] = r['topic']\n",
    "    corr_df.append(df)\n",
    "corr_df = pd.concat(corr_df)\n",
    "\n",
    "corr_df.to_csv('Results/term_correlations_frames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b47a021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
