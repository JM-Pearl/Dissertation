{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b65cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NUMEXPR_MAX_THREADS\"] = '36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4aeb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "%run procedural_stop_words.py\n",
    "\n",
    "from plotnine import ggplot, aes, geoms, theme, ggtitle, ylim, xlim, ylab\n",
    "from plotnine import element_blank, element_line, element_text, scales, annotate,facet_wrap\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "import p_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b354482",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('Results/All_speeches_labelled.csv')\n",
    "all_df = all_df.loc[all_df.party_y != 'I']\n",
    "\n",
    "combinations = []\n",
    "for year in range(1983,2017):\n",
    "    for topic in all_df.dynamic_label.unique():\n",
    "        combinations.append((year,topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4508bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DTM(sub,binary=True):\n",
    "    \"\"\"\n",
    "    Make a Document Term Matrix from topic subset speeches\n",
    "    \n",
    "    args:\n",
    "        - sub: pandas dataframe with speeches and metadata\n",
    "        - binary: 1 or count for term occurence in document\n",
    "    returns:\n",
    "        - Document Term Matrix\n",
    "    \n",
    "    \"\"\"\n",
    "    # speaker and party ID\n",
    "    features = sub.groupby('speaker',as_index=False).party_y.first()\n",
    "    \n",
    "    # document term matrix\n",
    "    vectorizer = CountVectorizer(min_df=5,binary=binary,stop_words=procedural_stop_words)\n",
    "    DTM = vectorizer.fit_transform(sub.speech_processed)\n",
    "    DTM = pd.DataFrame(DTM.toarray())\n",
    "\n",
    "    # associate DTM with speaker and get term-speech frequency by speaker\n",
    "    DTM['speaker'] = list(sub['speaker'])\n",
    "    DTM = (DTM\n",
    "           .groupby('speaker',as_index=False)\n",
    "           .sum()\n",
    "           .merge(features,on='speaker',how='left')\n",
    "           .drop('speaker',1)\n",
    "          )\n",
    "\n",
    "    # assign terms to DTM\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    DTM.columns = terms + ['party_y']\n",
    "    \n",
    "    return DTM\n",
    "\n",
    "\n",
    "def chi_sq(x):\n",
    "    \"\"\"\n",
    "    Run chi-squared test from Gentzkow et al. 2010.\n",
    "    to be run on each term in frequency frame\n",
    "    \"\"\"\n",
    "    \n",
    "    numer = ((x['R']*x['Dn']) - (x['D']*x['Rn']))**2\n",
    "    denom = (x['R'] + x['D']) * (x['R'] + x['Rn']) * (x['D'] + x['Dn']) * (x['Dn'] + x['Rn'])\n",
    "    return numer/denom\n",
    "\n",
    "\n",
    "def chiSq_df(dtm,permute=False):\n",
    "    \"\"\"\n",
    "    sets up dataframe containing term frequencies and\n",
    "    expected frequencies for chi-square test\n",
    "    \n",
    "    args:\n",
    "        - dtm: Document Term Matrix\n",
    "        - permute: if True shuffle speaker values (default False)\n",
    "    returns:\n",
    "        - term_frequencies dataframe with chi-square stats\n",
    "    \"\"\"\n",
    "    \n",
    "    if permute: # shuffle party labels\n",
    "        dtm.party_y = np.random.permutation(dtm.party_y.values)\n",
    "        \n",
    "    term_frequencies = dtm.groupby('party_y').sum().T  # term frequency by party\n",
    "    total_frequencies = term_frequencies.sum()  # total frequencies\n",
    "\n",
    "    # set up for chi-square test\n",
    "    term_frequencies['Dn'] =  total_frequencies['D'] - term_frequencies['D'] \n",
    "    term_frequencies['Rn'] = total_frequencies['R'] - term_frequencies['R']\n",
    "    term_frequencies['chi2'] = term_frequencies.apply(chi_sq,1)\n",
    "\n",
    "    term_frequencies['terms'] = dtm.columns[:-1]\n",
    "    \n",
    "    return term_frequencies\n",
    "\n",
    "def perform_correlations(dtm,permute=False):\n",
    "    \"\"\"\n",
    "    runs correlation analysis on every term with party ID\n",
    "    method from Jensen et al. 2012\n",
    "    \n",
    "    args:\n",
    "        - dtm: Document Term matrix containing speech-term frequencies\n",
    "        - permute: if True, shuffle party labels (default False)\n",
    "    returns:\n",
    "        - dataframe containing Pearson r values for every word\n",
    "    \"\"\"\n",
    "    \n",
    "    # contrast code for party\n",
    "    party_ID = [-1 if party == 'D' else 1 for party in dtm.party_y]\n",
    "    dtm = dtm.drop('party_y',1)\n",
    "    \n",
    "    # normalize frequencies\n",
    "    dtm_normed = np.apply_along_axis(lambda x: (x - np.mean(x))/np.std(x),0,dtm.to_numpy())\n",
    "    \n",
    "    # perform correlation analysis\n",
    "    if permute:\n",
    "        party_ID = np.random.permutation(party_ID)\n",
    "        \n",
    "    # perform correlations\n",
    "    corrs = np.apply_along_axis(lambda x: pearsonr(x,party_ID)[0],0,dtm_normed)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "            \"term\":dtm.columns,\n",
    "            \"correlation\":corrs,\n",
    "            'freq':dtm.sum(0)\n",
    "        }).dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "212b2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_similarity(year,topic,binary=True):\n",
    "    \"\"\"\n",
    "    run analysis for a given year and topic\n",
    "    \n",
    "    args:\n",
    "        - year: year to subset speeches\n",
    "        - topic: topic to subset speeches\n",
    "        - binary: if True, 1 for speech containing word else frequency within speech\n",
    "    returns:\n",
    "        - dictionary containing summary statistics and correlation dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # subset speeches\n",
    "    sub_df = all_df.loc[(all_df.year_y == year) & (all_df.dynamic_label == topic)]\n",
    "\n",
    "    if len(sub_df) > 0:\n",
    "\n",
    "        DTM = make_DTM(sub_df,binary=binary) # Make DTM\n",
    "        term_df = chiSq_df(DTM) # Make Chi_square frequency table\n",
    "\n",
    "        pre_drop_terms = DTM.columns[:-1] # record keeping\n",
    "        \n",
    "        # remove low value chi square terms\n",
    "        term_df['chi2'] = term_df.loc[term_df.chi2 > 0]\n",
    "        drop_cols = list(term_df.loc[term_df.chi2 <= 0,'terms'].values)\n",
    "        DTM = DTM.drop(drop_cols,1)\n",
    "\n",
    "        corr_df = perform_correlations(DTM) # make correlation DF\n",
    "        \n",
    "        # calculate metrics\n",
    "        corr_df['weighted'] = corr_df['correlation']*corr_df['freq']\n",
    "        partisanship = corr_df['weighted'].sum()/corr_df['freq'].sum()\n",
    "        polarization = corr_df['weighted'].abs().sum()/corr_df['freq'].sum()\n",
    "        distance = cosine(term_df['D'],term_df['R'])\n",
    "        \n",
    "        return {\"results\":{'distance':distance,\n",
    "                    'polarization':polarization,\n",
    "                    'partisanship':partisanship,\n",
    "                    \"pre_termlength\":len(pre_drop_terms),\n",
    "                    'post_termlength':len(corr_df)},\n",
    "                'correlations':corr_df,\n",
    "                'topic':topic,\n",
    "                'year':year\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c2259",
   "metadata": {},
   "source": [
    "# Run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "300d0c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1983 procedural:   0%|          | 0/2142 [00:00<?, ?it/s]<ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1983 defense_weapons:   0%|          | 7/2142 [00:06<29:19,  1.21it/s]          <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1983 transportation:   1%|          | 12/2142 [00:09<22:15,  1.59it/s] <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1984 procedural:   3%|▎         | 63/2142 [00:19<01:55, 17.94it/s]             <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1985 procedural:   6%|▌         | 126/2142 [00:40<02:01, 16.55it/s]              <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1985 defense_weapons:   6%|▌         | 133/2142 [00:45<15:47,  2.12it/s]          <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1985 central_america:   6%|▋         | 135/2142 [00:47<18:07,  1.85it/s]<ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1987 procedural:  12%|█▏        | 252/2142 [01:19<02:16, 13.86it/s]               <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1987 defense_weapons:  12%|█▏        | 259/2142 [01:23<12:47,  2.45it/s]          <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1987 central_america:  12%|█▏        | 261/2142 [01:25<18:37,  1.68it/s]<ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1987 tribute:  13%|█▎        | 284/2142 [01:33<09:16,  3.34it/s]                <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1988 international_humanRights:  15%|█▍        | 317/2142 [01:41<05:31,  5.50it/s]<ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1991 trade:  24%|██▍       | 510/2142 [02:40<12:32,  2.17it/s]                    <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1991 higher_education:  25%|██▍       | 525/2142 [02:46<09:20,  2.88it/s]   <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1991 nuclear_weapons:  26%|██▌       | 553/2142 [02:55<09:47,  2.70it/s]        <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1992 transportation:  27%|██▋       | 579/2142 [03:03<08:02,  3.24it/s]           <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1993 procedural:  29%|██▉       | 629/2142 [03:17<04:00,  6.29it/s]             <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1993 justice_courts:  30%|███       | 646/2142 [03:23<07:52,  3.17it/s]           <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1995 procedural:  35%|███▌      | 756/2142 [03:55<04:01,  5.73it/s]               <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1995 taxes:  35%|███▌      | 760/2142 [03:58<09:02,  2.55it/s]                    <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1995 defense_weapons:  36%|███▌      | 763/2142 [04:00<11:13,  2.05it/s]<ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1995 partisans:  37%|███▋      | 786/2142 [04:09<06:04,  3.72it/s]              <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1995 health_insurance:  37%|███▋      | 801/2142 [04:13<04:18,  5.18it/s] <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1995 welfare:  38%|███▊      | 806/2142 [04:15<04:39,  4.77it/s]           <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1995 campaign_finance:  38%|███▊      | 811/2142 [04:17<07:28,  2.97it/s] <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1995 defense_conflicts:  38%|███▊      | 814/2142 [04:19<10:43,  2.07it/s]<ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1995 appropriations:  38%|███▊      | 815/2142 [04:20<13:50,  1.60it/s]   <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1997 taxes:  41%|████▏     | 887/2142 [04:42<04:29,  4.66it/s]                    <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1997 schools:  42%|████▏     | 908/2142 [04:49<03:42,  5.54it/s]            <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1998 taxes:  44%|████▍     | 950/2142 [05:02<05:08,  3.87it/s]                    <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1998 schools:  45%|████▌     | 971/2142 [05:09<04:55,  3.97it/s]            <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1999 procedural:  47%|████▋     | 1008/2142 [05:21<06:59,  2.70it/s]            <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1999 taxes:  47%|████▋     | 1013/2142 [05:23<06:25,  2.93it/s]                    <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "1999 tribute:  49%|████▊     | 1040/2142 [05:32<05:13,  3.51it/s]                <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2000 international_humanRights:  50%|█████     | 1073/2142 [05:44<06:52,  2.59it/s]<ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2001 procedural:  53%|█████▎    | 1134/2142 [06:04<04:51,  3.46it/s]               <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2002 civil_rights_flag:  58%|█████▊    | 1249/2142 [06:36<04:54,  3.03it/s]        <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2002 defense_conflicts:  59%|█████▊    | 1255/2142 [06:38<05:19,  2.78it/s]<ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2003 procedural:  59%|█████▉    | 1260/2142 [06:41<06:08,  2.39it/s]       <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2004 tribute:  63%|██████▎   | 1355/2142 [07:18<05:11,  2.53it/s]                  <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2005 energy_oilgas:  65%|██████▍   | 1387/2142 [07:27<04:29,  2.81it/s]     <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2005 taxes:  65%|██████▍   | 1390/2142 [07:30<07:14,  1.73it/s]                    <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2005 civil_rights:  66%|██████▌   | 1408/2142 [07:35<02:42,  4.51it/s]       <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2005 disaster_relief:  67%|██████▋   | 1442/2142 [07:45<02:21,  4.94it/s]        <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2006 defense_conflicts:  70%|███████   | 1507/2142 [08:05<02:25,  4.36it/s]        <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2007 procedural:  71%|███████   | 1512/2142 [08:08<04:19,  2.42it/s]       <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2007 energy_oilgas:  71%|███████   | 1513/2142 [08:10<09:16,  1.13it/s]<ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2007 trade:  71%|███████   | 1518/2142 [08:12<04:52,  2.13it/s]                    <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2007 veterans:  72%|███████▏  | 1532/2142 [08:17<04:33,  2.23it/s]           <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2007 transportation_air:  73%|███████▎  | 1558/2142 [08:29<03:33,  2.74it/s]     <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2007 defense_conflicts:  73%|███████▎  | 1570/2142 [08:32<02:19,  4.09it/s] <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2008 energy_oilgas:  74%|███████▎  | 1576/2142 [08:36<03:42,  2.55it/s]    <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2009 civil_rights:  77%|███████▋  | 1660/2142 [09:00<01:56,  4.14it/s]             <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2010 partisans:  81%|████████  | 1732/2142 [09:20<01:58,  3.46it/s]                <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2010 health_insurance:  81%|████████▏ | 1745/2142 [09:24<01:22,  4.82it/s] <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2015 tribute:  96%|█████████▌| 2047/2142 [10:45<00:31,  2.98it/s]                  <ipython-input-31-b505531a1d71>:27: RuntimeWarning: overflow encountered in long_scalars\n",
      "2016 healthcare: 100%|██████████| 2142/2142 [11:06<00:00,  3.21it/s]               \n"
     ]
    }
   ],
   "source": [
    "Results = []\n",
    "pbar = tqdm(combinations)\n",
    "for combination in pbar:\n",
    "    pbar.set_description(\"%s %s\"%combination)\n",
    "    year,topic = combination\n",
    "    f = run_similarity(year,topic,binary=True)\n",
    "    if f:\n",
    "        Results.append(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a8c90",
   "metadata": {},
   "source": [
    "# Permutation analysis for null models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbe508a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_similarity_perm(year,topic,binary=True,perms=200):\n",
    "    sub_df = all_df.loc[(all_df.year_y == year) & (all_df.dynamic_label == topic)]\n",
    "    if len(sub_df) > 0:\n",
    "        \n",
    "        # get terms maintained from true results\n",
    "        true_corrs = [b['correlations'] for b in Binary_Results \n",
    "                   if b['topic'] == topic and b['year'] == year]\n",
    "\n",
    "        keep_terms = true_corrs[0].term.values\n",
    "        \n",
    "        DTM = make_DTM(sub_df,binary=binary) # Make DTM\n",
    "        pre_drop_terms = DTM.columns[:-1] # record keeping\n",
    "        drop_cols = [i for i in pre_drop_terms if i not in keep_terms]\n",
    "        DTM = DTM.drop(drop_cols,1)\n",
    "        \n",
    "        Nulls = []\n",
    "        for perm in range(perms):\n",
    "            term_df = chiSq_df(DTM,permute=True) # Make Chi_square frequency table\n",
    "            # remove low value chi square terms\n",
    "            term_df['chi2'] = term_df.loc[-term_df.terms.isin(drop_cols)]\n",
    "\n",
    "            corr_df = perform_correlations(DTM,permute=True) # make correlation DF\n",
    "\n",
    "            # calculate metrics\n",
    "            corr_df['weighted'] = corr_df['correlation']*corr_df['freq']\n",
    "            partisanship = corr_df['weighted'].sum()/corr_df['freq'].sum()\n",
    "            polarization = corr_df['weighted'].abs().sum()/corr_df['freq'].sum()\n",
    "            distance = cosine(term_df['D'],term_df['R'])\n",
    "\n",
    "            Nulls.append({'distance':distance,\n",
    "                        'polarization':polarization,\n",
    "                        'partisanship':partisanship,\n",
    "                        \"pre_termlength\":len(pre_drop_terms),\n",
    "                        'post_termlength':len(corr_df),\n",
    "                        'topic':topic,\n",
    "                        'year':year,\n",
    "                        'iter':perm})\n",
    "        return pd.DataFrame(Nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14555f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f008423722491c86bac60b90532524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_(x):\n",
    "    year,topic = x\n",
    "    f = run_similarity_perm(year,topic,binary=True)\n",
    "    if type(f) == pd.core.frame.DataFrame:\n",
    "        return f\n",
    "\n",
    "Null_Results = p_tqdm.p_map(run_,combinations,num_cpus=30)\n",
    "\n",
    "Null_DF = pd.concat(Null_Results)\n",
    "Null_DF.to_csv('Results/Null_Frame_Results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d76ec35",
   "metadata": {},
   "source": [
    "### Saving to disc and as CSV for visualization in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5182a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results/Frame_results.pkl', 'wb') as File:\n",
    "    joblib.dump(Results,File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57334cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Null_DF['polarization_st'] = Null_DF.groupby('iter').polarization.transform(lambda x: (x-x.mean())/x.std())\n",
    "Null_DF['partisanship_st'] = Null_DF.groupby('iter').partisanship.transform(lambda x: (x-x.mean())/x.std())\n",
    "\n",
    "Result_DF = pd.DataFrame([_['results'] for _ in Results])\n",
    "Result_DF['polarization_st'] = Result_DF.polarization.transform(lambda x: (x-x.mean())/x.std())\n",
    "Result_DF['partisanship_st'] = Result_DF.partisanship.transform(lambda x: (x-x.mean())/x.std())\n",
    "\n",
    "Null_DF['type'] = 'null'\n",
    "Result_DF['iter'] = 99\n",
    "Result_DF['type'] = 'true'\n",
    "\n",
    "Null_DF = Null_DF[['type','iter','year','topic','distance','polarization','polarization_st','partisanship','partisanship_st']]\n",
    "Result_DF = Result_DF[['type','iter','year','topic','distance','polarization','polarization_st','partisanship','partisanship_st']]\n",
    "\n",
    "combined = pd.concat([Result_DF,Null_DF])\n",
    "\n",
    "combined.to_csv('Results/True_and_Nulls_Frame.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = []\n",
    "for r in Results:\n",
    "    df = r['correlations']\n",
    "    df['year'] = r['year']\n",
    "    df['topic'] = r['topic']\n",
    "    corr_df.append(df)\n",
    "corr_df = pd.concat(corr_df)\n",
    "\n",
    "corr_df.to_csv('Results/term_correlations_frames.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
