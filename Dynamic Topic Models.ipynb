{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35ae118",
   "metadata": {},
   "source": [
    "# Dynamic Topic Model\n",
    "\n",
    "This notebook includes code for creating window topic models for each year of congressional speech in the House for each party, and a dynamic topic model as per the Dynamic Non-Negative Matrix Factorization approach described by Greene (2019). \n",
    "\n",
    "\n",
    "Previous development of these models indicates that the most interpretable and coherent models generally fall between 45 and 60 topics for each year/party respectively. Little difference is made in the interpretability and coherence of models within this range. For this reason a middleground of 50 topics is used for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e3e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from multiprocess import Pool\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "client = boto3.client('s3')\n",
    "\n",
    "# Code from https://github.com/derekgreene/dynamic-nmf\n",
    "%run Greene_dnmf.py\n",
    "\n",
    "# get procedural stop words\n",
    "%run procedural_stop_words.py\n",
    "\n",
    "# model evaluation tool \n",
    "%run Model_description_evaluation_widget.py\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e9aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_rankings(H,terms,ntop):\n",
    "    term_rankings = []\n",
    "    for topic_index in range(H.shape[0]):\n",
    "        top_indices = np.argsort(H[topic_index,:])[::-1]\n",
    "        term_ranking = [terms[i] for i in top_indices[:ntop]]\n",
    "        term_rankings.append(term_ranking)\n",
    "    return term_rankings\n",
    "\n",
    "def get_top_words(vect):\n",
    "    splits = [[z for z in i.split() if z in vocab] for i in vect]\n",
    "    docs = [x for sublist in splits for x in sublist]\n",
    "    counts = Counter(docs)\n",
    "    top_10 = [i[0] for i in counts.most_common()][:20]\n",
    "    return top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b99ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_window_NMF(congress):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reads in data for a given congress, runs NMF models for every year \n",
    "    in that congress for a specific party.\n",
    "    \n",
    "    congress: what congress to use\n",
    "    \"\"\"\n",
    "\n",
    "    k = 45\n",
    "    \n",
    "    # read in data from S3\n",
    "    DF = pd.read_csv(client.get_object(Bucket='ascsagemaker',\n",
    "                                       Key=f'JMP_congressional_nmf/House_bigrams/{congress:0>3}_fixed_party.csv')['Body'])\n",
    "    \n",
    "    # remove speeches with no party labels\n",
    "    DF = DF.loc[-DF.party_y.isnull()]\n",
    "\n",
    "    # partse to only the house and party of interest\n",
    "    DF = DF.loc[(DF.chamber_x == 'H')]\n",
    "\n",
    "    DF['date'] = pd.to_datetime(DF.date)  # to date time\n",
    "    \n",
    "    years = pd.to_datetime(DF.date).dt.year.unique() # what years are included in this congress\n",
    "    if congress == 112:  #  112th congress includes overlap year with 113th\n",
    "        years = years[:2]\n",
    "    models = []\n",
    "    \n",
    "    #  for each year run a NMF window topic model\n",
    "    for year in years:\n",
    "        sub_df = DF.loc[DF.date.dt.year == year]\n",
    "\n",
    "        # prepare TfIDF DTM\n",
    "        vectorizer = TfidfVectorizer(min_df=0.001,max_df=0.3,stop_words=procedural_stop_words,use_idf=True,)\n",
    "        dtm = vectorizer.fit_transform(sub_df.speech_processed)\n",
    "        vocab = vectorizer.get_feature_names()\n",
    "\n",
    "        # run model\n",
    "        model = NMF(n_components=k,max_iter=5000,init='nndsvd')\n",
    "        W = model.fit_transform(dtm)\n",
    "        H = model.components_\n",
    "        print(f'{year} - {len(sub_df)} speeches, vocab {len(vocab)}')\n",
    "        \n",
    "        # return information packet\n",
    "        models.append({\"W\":W,\"H\":H,\n",
    "                       \"vocab\":vocab,\n",
    "                       \"window_labels\":[f'{year}_{i}' for i in range(100)],\n",
    "                       \"year\":year,\n",
    "                       \"DF_index\":DF.index,\n",
    "                       \"topics\":term_rankings(H,vocab,ntop=10)})\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9538d5b3",
   "metadata": {},
   "source": [
    "## Run batch process of every year (33 models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d547d225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989 - 14525 speeches, vocab 8266\n",
      "1987 - 19235 speeches, vocab 8088\n",
      "1985 - 21288 speeches, vocab 7567\n",
      "1999 - 18494 speeches, vocab 8007\n",
      "1983 - 19450 speeches, vocab 7565\n",
      "1990 - 18562 speeches, vocab 8234\n",
      "1993 - 18404 speeches, vocab 7705\n",
      "1995 - 30208 speeches, vocab 6725\n",
      "1988 - 16095 speeches, vocab 8069\n",
      "1997 - 18073 speeches, vocab 7573\n",
      "1996 - 17943 speeches, vocab 7580\n",
      "1994 - 16559 speeches, vocab 8204\n",
      "1991 - 18944 speeches, vocab 8387\n",
      "1986 - 17440 speeches, vocab 7931\n",
      "2005 - 17568 speeches, vocab 8775\n",
      "1998 - 18098 speeches, vocab 7675\n",
      "2001 - 15038 speeches, vocab 8018\n",
      "2000 - 17704 speeches, vocab 8048\n",
      "2003 - 17069 speeches, vocab 8340\n",
      "2002 - 12114 speeches, vocab 8088\n",
      "1992 - 15767 speeches, vocab 8416\n",
      "2006 - 15252 speeches, vocab 8530\n",
      "2013 - 13921 speeches, vocab 7807\n",
      "1984 - 20144 speeches, vocab 7501\n",
      "2009 - 14239 speeches, vocab 7854\n",
      "2011 - 17205 speeches, vocab 7424\n",
      "2007 - 24529 speeches, vocab 8431\n",
      "2015 - 14138 speeches, vocab 7829\n",
      "2004 - 14759 speeches, vocab 8516\n",
      "2016 - 8806 speeches, vocab 8173\n",
      "2008 - 14826 speeches, vocab 8684\n",
      "2010 - 15235 speeches, vocab 8174\n",
      "2012 - 12306 speeches, vocab 7775\n",
      "2014 - 11670 speeches, vocab 8205\n"
     ]
    }
   ],
   "source": [
    "with Pool(10) as p:\n",
    "    output = p.map(run_window_NMF,range(98,115))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335265ad",
   "metadata": {},
   "source": [
    "## Prepare window NMF for dynamic level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "879e9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [model for sublist in output for model in sublist]\n",
    "\n",
    "collection = TopicCollection()\n",
    "for model in outputs:\n",
    "    collection.add_topic_model(model['H'],model['vocab'],model['window_labels'])\n",
    "    \n",
    "Mat, full_vocab = collection.create_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef42e912",
   "metadata": {},
   "source": [
    "## Run Dynamic Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "95ad5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level = NMF(n_components=80,max_iter=5000,init='nndsvd')\n",
    "W = second_level.fit_transform(Mat)\n",
    "H = second_level.components_\n",
    "terms = term_rankings(H,full_vocab,ntop=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f2d2697",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1e56edbfae42cca03449b7e9d9d1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Dropdown(description='Dynamic Topic #:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W = Models['dynamic_model']['W']\n",
    "terms = Models['dynamic_model']['terms']\n",
    "term_list = [term for sublist in Models['window_models'] for term in sublist['topics']]\n",
    "mapped_df = pd.DataFrame({\"window_descriptions\":term_list,\n",
    "                          'window_id':[' - '.join(i.split('_')) for i in collection.topic_ids],\n",
    "                          'dynamic_id':W.argmax(1)})\n",
    "\n",
    "\n",
    "box = run_widget(terms,mapped_df)\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3225a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_labels = ['tribute', 'veterans', 'taxes', 'natural_resources_water', 'small_business',\n",
    " 'research_science', 'abortion', 'food_assistance', 'agriculture', 'housing', 'taxes', 'veterans',\n",
    " 'employment', 'crime', 'israel', 'healthcare', 'justice_courts', 'social_security', 'domestic_commerce',\n",
    " 'national_debt', 'public_lands', 'procedural', 'procedural', 'transportation', 'drugs', 'space',\n",
    " 'energy_oilgas', 'procedural', 'trade', 'nuclear_weapons', 'procedural', 'international_humanRights',\n",
    " 'medicare', 'immigration', 'NA', 'intelligence', 'health_insurance', 'tribute', 'waters_coastguard',\n",
    " 'unemployment', 'taxes', 'environment', 'arts', 'higher_education', 'procedural', 'constitution',\n",
    " 'armenian_genocide', 'budget', 'schools', 'womens_issues', 'guns', 'defense_conflicts', 'disasters',\n",
    " 'appropriations', 'partisans', 'transportation_air', 'defense_weapons', 'procedural', 'procedural',\n",
    " 'central_america', 'public_health', 'china', 'international_humanRights', 'trade', 'NA', 'labor',\n",
    " 'civil_rights_flag', 'disaster_relief', 'welfare', 'procedural', 'NA', 'energy_oilgas', 'civil_rights',\n",
    " 'labor_wages', 'campaign_finance', 'research_technology', 'elections', 'banking_finance', 'procedural',\n",
    " 'lending']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1467810a",
   "metadata": {},
   "source": [
    "### DataFrame to map window topics to dynamic topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e280f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_topics = W.argmax(1)\n",
    "assigned_labels = [dynamic_labels[i] for i in assigned_topics]\n",
    "mapper = []\n",
    "for i in range(len(collection.topic_ids)):\n",
    "    year,topic = collection.topic_ids[i].split('_')\n",
    "    topic_label = assigned_labels[i]\n",
    "    topic_ix = assigned_topics[i]\n",
    "    mapper.append({'year':year,'topic_id':int(topic),'dynamic_label':topic_label})\n",
    "\n",
    "mapper = pd.DataFrame(mapper)\n",
    "\n",
    "def get_topic_terms(x):\n",
    "    year = int(x['year'])\n",
    "    ix = int(x['topic_id'])\n",
    "    for out in outputs:\n",
    "        if out['year'] == year:\n",
    "            return out['topics'][ix]\n",
    "        \n",
    "        \n",
    "mapper['window_terms'] = mapper.apply(get_topic_terms,1)\n",
    "mapper = mapper.sort_values(by='year',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bea957e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>dynamic_label</th>\n",
       "      <th>window_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1983</td>\n",
       "      <td>0</td>\n",
       "      <td>justice_courts</td>\n",
       "      <td>[procedure, investigation, staff, court, condu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1983</td>\n",
       "      <td>25</td>\n",
       "      <td>procedural</td>\n",
       "      <td>[substitute, original, mica, wylie, amend, gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1983</td>\n",
       "      <td>26</td>\n",
       "      <td>trade</td>\n",
       "      <td>[trade, import, export, foreign, japanese, mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1983</td>\n",
       "      <td>27</td>\n",
       "      <td>civil_rights</td>\n",
       "      <td>[king, martin_luther, dr_king, holiday, nation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1983</td>\n",
       "      <td>28</td>\n",
       "      <td>civil_rights</td>\n",
       "      <td>[civil_right, commissioner, independence, inde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>2016</td>\n",
       "      <td>17</td>\n",
       "      <td>food_assistance</td>\n",
       "      <td>[food, nutrition, consumer, restaurant, calori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>2016</td>\n",
       "      <td>18</td>\n",
       "      <td>domestic_commerce</td>\n",
       "      <td>[fcc, internet, rate, broadband, consumer, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>2016</td>\n",
       "      <td>19</td>\n",
       "      <td>banking_finance</td>\n",
       "      <td>[bank, financial, financial_institution, regul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>higher_education</td>\n",
       "      <td>[student, college, high_education, university,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>2016</td>\n",
       "      <td>44</td>\n",
       "      <td>international_humanRights</td>\n",
       "      <td>[genocide, isis, christian, religious, middle_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1530 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  topic_id              dynamic_label  \\\n",
       "0     1983         0             justice_courts   \n",
       "25    1983        25                 procedural   \n",
       "26    1983        26                      trade   \n",
       "27    1983        27               civil_rights   \n",
       "28    1983        28               civil_rights   \n",
       "...    ...       ...                        ...   \n",
       "1502  2016        17            food_assistance   \n",
       "1503  2016        18          domestic_commerce   \n",
       "1504  2016        19            banking_finance   \n",
       "1494  2016         9           higher_education   \n",
       "1529  2016        44  international_humanRights   \n",
       "\n",
       "                                           window_terms  \n",
       "0     [procedure, investigation, staff, court, condu...  \n",
       "25    [substitute, original, mica, wylie, amend, gen...  \n",
       "26    [trade, import, export, foreign, japanese, mar...  \n",
       "27    [king, martin_luther, dr_king, holiday, nation...  \n",
       "28    [civil_right, commissioner, independence, inde...  \n",
       "...                                                 ...  \n",
       "1502  [food, nutrition, consumer, restaurant, calori...  \n",
       "1503  [fcc, internet, rate, broadband, consumer, reg...  \n",
       "1504  [bank, financial, financial_institution, regul...  \n",
       "1494  [student, college, high_education, university,...  \n",
       "1529  [genocide, isis, christian, religious, middle_...  \n",
       "\n",
       "[1530 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3f4199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Final Model/models\n",
    "Final_output = {\"window_models\":outputs,\n",
    "                'dynamic_model':{'k':95,'H':H,'W':W,'collection_mat':Mat,'collection_vocab':full_vocab,'terms':terms},\n",
    "                'mapper':mapper}\n",
    "\n",
    "with open('Official_TopicModel_80k.pkl','wb') as File:\n",
    "    joblib.dump(Final_output,File)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04955ba0",
   "metadata": {},
   "source": [
    "## Assign labels to speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea9e6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load back in all the data\n",
    "dfs = []\n",
    "for congress in range(98,115): \n",
    "\n",
    "    DF2 = pd.read_csv(client.get_object(Bucket='ascsagemaker',\n",
    "                                           Key=f'JMP_congressional_nmf/House_bigrams/{congress:0>3}_fixed_party.csv')['Body'])\n",
    "    DF2['date'] = pd.to_datetime(DF2['date'])\n",
    "    \n",
    "    if congress == 112:\n",
    "        DF2 = DF2.loc[DF2.date.dt.year != 2013]\n",
    "        \n",
    "    dfs.append(DF2)\n",
    "    \n",
    "ldf = pd.concat(dfs)\n",
    "ldf = ldf.loc[-ldf.party_y.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8030acdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:03<00:00, 10.79it/s]\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None # suppress warning about slicing\n",
    "\n",
    "code_mapper = Final_output['mapper'][['year','topic_id','dynamic_label']]\n",
    "code_mapper['int_year'] = code_mapper.year.apply(lambda x: int(x))\n",
    "\n",
    "labelled_df = []\n",
    "for year in tqdm(ldf.date.dt.year.unique()):\n",
    "    # subset given year and find window W matrix\n",
    "    sub_df = ldf.loc[ldf.date.dt.year == year]\n",
    "    window_model = [model for model in Models['window_models'] if model['year'] == year][0]\n",
    "    sub_df.loc[:,'window_topic_id'] = window_model['W'].argmax(1)\n",
    "    sub_df.loc[:,'topic_weight'] = [window_model['W'][ix,val] for ix,val in enumerate(window_model['W'].argmax(1))]\n",
    "    # merge on the assigned dynamic topic and year\n",
    "    sub_df = sub_df.merge(code_mapper,left_on=['year','window_topic_id'],right_on=['int_year','topic_id'],how='left')\n",
    "    labelled_df.append(sub_df)\n",
    "    \n",
    "final_DF = pd.concat(labelled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5c5b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_DF.to_csv('Results/All_speeches_labelled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e7dd2c",
   "metadata": {},
   "source": [
    "## Semantic Validity In Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb3789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_DF = pd.read_csv('Results/All_speeches_labelled.csv')\n",
    "\n",
    "with open('Results/Official_TopicModel_80k.pkl','rb') as File:\n",
    "    Models = joblib.load(File)\n",
    "    \n",
    "dynamic_topics = Models['dynamic_model']['terms']\n",
    "dynamic_df = pd.DataFrame({\"labels\":dynamic_labels,'terms':dynamic_topics})\n",
    "mapper = Models['mapper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a56452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['emergency', 'disaster', 'fema', 'flood', 'flood_insurance', 'damage', 'offset', 'hurricane', 'relief', 'victim'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_df.loc[dynamic_df.labels == 'disaster_relief'].terms.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cbe9e461",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Box = Run_speech_widget(final_DF,mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9477a603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bcb6b0a46e4e67ace8a248a818bcdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Dropdown(description='Dynamic Topic #:', index=5, options=('procedural', 'energy_oilgas', 'interâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786f3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
